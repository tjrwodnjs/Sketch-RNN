{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "import dezero.models as M\n",
    "from dezero.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import cuda\n",
    "from typing import List, Optional, Tuple, Any\n",
    "import math\n",
    "\n",
    "class StrokesDataset(dezero.DataLoader):\n",
    "    def __init__(self, data, batch_size, max_seq_length: int, scale: Optional[float] = None, shuffle=True, gpu=False):\n",
    "        stroke_data = []\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_size = len(data)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "        self.gpu = gpu\n",
    "        \n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        \n",
    "        for seq in data:\n",
    "            # we will deem a sequence that is less than 10 as too short and thus ignore it\n",
    "            if 10 < len(seq) <= max_seq_length:\n",
    "                # clamp the delta x and delta y to [-1000, 1000]\n",
    "                seq = np.minimum(seq, 1000)\n",
    "                seq = np.maximum(seq, -1000)\n",
    "                \n",
    "                seq = np.array(seq, dtype=np.float32)\n",
    "                stroke_data.append(seq)\n",
    "        \n",
    "        if scale is None:\n",
    "            # calculate the scale factor\n",
    "            # the scale factor is the standard deviation of the x and y coordinates\n",
    "            # mean is not adjusted for simplicity\n",
    "            # 0:2 means the first two columns of the array which are x and y coordinates\n",
    "            scale = np.std(np.concatenate([np.ravel(s[:,0:2]) for s in stroke_data]))\n",
    "        \n",
    "        longest_seq_len = max([len(seq) for seq in stroke_data])\n",
    "        \n",
    "        # we add two extra columns to the dataset since we currently there are only 3 columns in the dataset\n",
    "        # additional two columns are for changing the last point 1/0 to a one-hot vector\n",
    "        temp_stroke_dataset = xp.zeros((len(stroke_data), longest_seq_len + 2, 5), dtype=np.float32)\n",
    "        \n",
    "        # self.mask is used to mark areas of the sequence that are not used\n",
    "        # we first initialize it to zero\n",
    "        temp_mask_dataset = xp.zeros((len(stroke_data), longest_seq_len + 1))\n",
    "        \n",
    "        self.dataset = []\n",
    "        \n",
    "        # start of sequence is [0, 0, 1, 0, 0]\n",
    "        \n",
    "        for i, seq in enumerate(stroke_data):\n",
    "            seq = xp.array(seq, dtype=xp.float32)\n",
    "            len_seq = len(seq)\n",
    "            \n",
    "            # we start from 1 to leave the first row for the start of sequence token\n",
    "            temp_stroke_dataset[i, 1:len_seq + 1, 0:2] = seq[:, :2] / scale # this is the x and y coordinates\n",
    "            temp_stroke_dataset[i, 1:len_seq + 1, 2] = 1 - seq[:, 2] # this is the pen down\n",
    "            temp_stroke_dataset[i, 1:len_seq + 1, 3] = seq[:, 2] # this is the pen up\n",
    "            temp_stroke_dataset[i, len_seq + 1, 4] = 1  # this is the end of sequence token\n",
    "            temp_mask_dataset[i, :len_seq + 1] = 1 # mask is on until the end of the sequence \n",
    "            # self.mask is used to mark areas of the sequence that are not used\n",
    "            # for example, if the sequence is shorter than the longest sequence, we use mask to ignore the rest of the sequence\n",
    "            # an example of mask is [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        \n",
    "        temp_stroke_dataset[:, 0, 2] = 1\n",
    "        \n",
    "        for i in range(len(stroke_data)):\n",
    "            self.dataset.append([temp_stroke_dataset[i], temp_mask_dataset[i]])\n",
    "        \n",
    "        \n",
    "        self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BivariateGaussianMixture:\n",
    "    def __init__(self, pi_logits, mu_x, mu_y, sigma_x, sigma_y, rho_xy):\n",
    "        self.pi_logits = pi_logits\n",
    "        self.mu_x = mu_x\n",
    "        self.mu_y = mu_y\n",
    "        self.sigma_x = sigma_x\n",
    "        self.sigma_y = sigma_y\n",
    "        self.rho_xy = rho_xy\n",
    "    \n",
    "    @property\n",
    "    def n_distributions(self):\n",
    "        return self.pi_logits.shape[-1]\n",
    "    \n",
    "    def set_temperature(self, temperature: float):\n",
    "        self.pi_logits /= temperature\n",
    "        self.sigma_x *= math.sqrt(temperature)\n",
    "        self.sigma_y *= math.sqrt(temperature)\n",
    "    \n",
    "    def gaussian_pdf(self, x_delta, y_delta):\n",
    "        # the result means the probability of y in the normal distribution\n",
    "        # we check the probability of y in the normal distribution\n",
    "        # if the probability is high, the result is close to 1\n",
    "        \n",
    "        while x_delta.shape != \n",
    "\n",
    "        norm1 = F.sub(x_delta, F.broadcast_to(self.mu_x, x_delta.shape))\n",
    "        norm2 = F.sub(y_delta, F.broadcast_to(self.mu_y, y_delta.shape))\n",
    "        xp = cuda.get_array_module(norm1)\n",
    "\n",
    "        \n",
    "        s1s2 = F.mul(self.sigma_x, self.sigma_y)\n",
    "        \n",
    "        # This is from: https://github.com/hardmaru/write-rnn-tensorflow/blob/master/model.py\n",
    "        # z = tf.square(tf.div(norm1, s1)) + tf.square(tf.div(norm2, s2))\n",
    "        #     - 2 * tf.div(tf.multiply(rho, tf.multiply(norm1, norm2)), s1s2)\n",
    "         \n",
    "        # below is the deconstruction of the above linez\n",
    "        z_first_term = F.pow(F.div(norm1, self.sigma_x), 2)\n",
    "        z_second_term = F.pow(F.div(norm2, self.sigma_y), 2)\n",
    "        z_last_term_inner = F.mul(self.rho_xy, F.mul(norm1, norm2))\n",
    "        z_last_term_middle = F.div(z_last_term_inner, s1s2)\n",
    "        tmp_z = np.ones(z_last_term_middle.shape) * -2\n",
    "        z_last_term = F.mul(tmp_z, z_last_term_middle)\n",
    "        z = F.add(F.add(z_first_term, z_second_term), z_last_term)\n",
    "        negRho = F.sub(np.ones(self.rho_xy.shape), F.pow(self.rho_xy, 2))\n",
    "\n",
    "        \n",
    "        result = F.exp(F.div(-z, 2 * negRho))\n",
    "        deno_first_term = np.ones(self.sigma_x.shape) * 2 * math.pi\n",
    "        denom_second_term = F.mul(s1s2, F.pow(negRho, 0.5))\n",
    "        denom = F.mul(deno_first_term, denom_second_term)\n",
    "        result = F.div(result, denom)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    # x1_data and x2_data are the real x and y coordinates of the stroke\n",
    "    def get_lossfunc(self, x_delta, y_delta):\n",
    "        result0 = self.gaussian_pdf(x_delta, y_delta)\n",
    "        \n",
    "        elipson = 1e-20\n",
    "        # check if result0 has inf or nan\n",
    "        result1 = F.mul(result0, self.pi_logits)\n",
    "        result1 = F.sum(result1, axis=1, keepdims=True)\n",
    "        result1 = -F.log(result1)\n",
    "        \n",
    "        return F.mean(result1)\n",
    "    \n",
    "    def get_pi_idx(self, x):\n",
    "        pdf = self.pi_logits\n",
    "        N = self.size\n",
    "        accumulate = 0\n",
    "        for i in range(0, N):\n",
    "            accumulate += pdf[i]\n",
    "            if accumulate >= x:\n",
    "                return i\n",
    "        print('error with sampling ensemble')\n",
    "        return -1\n",
    "    \n",
    "    # M means the number of samples\n",
    "    def sample(self, count, M=15):\n",
    "        xp = cuda.get_array_module(self.pi_logits)\n",
    "        # get the index of the distribution\n",
    "        \n",
    "        result = xp.random.rand(count, M, 2) # initially random [0,1]\n",
    "        # we will get result for delta_x and delta_y\n",
    "        rn = xp.random.rand(count, M, 2) \n",
    "        mu = 0\n",
    "        std = 0\n",
    "        idx = 0\n",
    "        \n",
    "        for j in range(M):\n",
    "            for i in range(count):\n",
    "                idx = self.get_pi_idx(result[i, j, 0])\n",
    "                mu = [self.mu_x[i, idx], self.mu_y[i, idx]]\n",
    "                std = [self.sigma_x[i, idx], self.sigma_y[i, idx]]\n",
    "                rho = self.rho_xy[i, idx]\n",
    "                \n",
    "                result[i, j, 0:2] = mu + rn[i, j] * std\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "(4, 64, 5) (4, 63)\n",
      "[[ 0.          0.          1.          0.          0.        ]\n",
      " [-0.5628141  -0.5959208   1.          0.          0.        ]\n",
      " [-0.62902755 -0.46349397  1.          0.          0.        ]\n",
      " [-1.0594149  -0.06621343  1.          0.          0.        ]\n",
      " [-0.43038726  0.16553356  1.          0.          0.        ]\n",
      " [-0.5628141   0.36417383  1.          0.          0.        ]\n",
      " [-0.2979604   0.36417383  1.          0.          0.        ]\n",
      " [-0.2979604   1.5891222   1.          0.          0.        ]\n",
      " [ 0.09932014  1.0594149   1.          0.          0.        ]\n",
      " [ 0.2979604   0.4966007   1.          0.          0.        ]\n",
      " [ 2.1188297   2.3174698   1.          0.          0.        ]\n",
      " [ 0.2979604   1.4898021   1.          0.          0.        ]\n",
      " [ 0.33106712  0.33106712  1.          0.          0.        ]\n",
      " [ 0.62902755  0.09932014  1.          0.          0.        ]\n",
      " [ 0.39728054 -0.4966007   1.          0.          0.        ]\n",
      " [ 0.72834766  0.          1.          0.          0.        ]\n",
      " [ 0.33106712  0.19864027  1.          0.          0.        ]\n",
      " [ 0.16553356 -0.06621343  1.          0.          0.        ]\n",
      " [ 0.4966007  -1.1256282   1.          0.          0.        ]\n",
      " [ 1.2249484  -1.2249484   1.          0.          0.        ]\n",
      " [ 0.16553356 -0.33106712  1.          0.          0.        ]\n",
      " [ 0.19864027 -0.4966007   1.          0.          0.        ]\n",
      " [ 0.19864027 -1.0925215   1.          0.          0.        ]\n",
      " [ 0.06621343 -1.2249484   1.          0.          0.        ]\n",
      " [-0.16553356 -0.43038726  1.          0.          0.        ]\n",
      " [-0.39728054 -0.4966007   1.          0.          0.        ]\n",
      " [-1.5891222  -1.0925215   1.          0.          0.        ]\n",
      " [-0.43038726 -0.03310671  1.          0.          0.        ]\n",
      " [-0.46349397  0.19864027  1.          0.          0.        ]\n",
      " [-0.5959208   0.4966007   1.          0.          0.        ]\n",
      " [-0.16553356  0.26485372  0.          1.          0.        ]\n",
      " [ 0.09932014 -0.62902755  1.          0.          0.        ]\n",
      " [-0.03310671 -0.52970743  1.          0.          0.        ]\n",
      " [ 0.89388126 -1.7877625   0.          1.          0.        ]\n",
      " [-0.5959208   0.92698795  1.          0.          0.        ]\n",
      " [ 0.13242686 -0.16553356  1.          0.          0.        ]\n",
      " [ 0.9932014  -0.2979604   1.          0.          0.        ]\n",
      " [ 0.62902755 -0.03310671  1.          0.          0.        ]\n",
      " [ 1.0263081   0.5959208   1.          0.          0.        ]\n",
      " [-0.26485372  0.          1.          0.          0.        ]\n",
      " [-0.62902755  0.23174699  1.          0.          0.        ]\n",
      " [-0.82766783  0.52970743  1.          0.          0.        ]\n",
      " [-0.72834766  0.03310671  1.          0.          0.        ]\n",
      " [-0.5959208  -0.26485372  0.          1.          0.        ]\n",
      " [ 0.          0.          0.          0.          1.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "44 44\n",
      "27 27\n",
      "34 34\n",
      "49 49\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./data/sketchrnn_apple.npz', encoding='latin1', allow_pickle=True)\n",
    "\n",
    "strokes = StrokesDataset(data['train'], batch_size=4, max_seq_length=200, gpu=False, shuffle=False)\n",
    "print(strokes.data_size)\n",
    "# first item\n",
    "\n",
    "x, t = strokes.__next__()\n",
    "print(x.shape, t.shape) # x is the stroke, t is the mask (x has one more column than t)\n",
    "print(x[0], t[0])\n",
    "\n",
    "# check if the mask is working\n",
    "batch_size = x.shape[0]\n",
    "\n",
    "for i in range(batch_size):\n",
    "    mask_zero_id = np.where(t[i] == 0)[0]\n",
    "    # first id\n",
    "    first_id = mask_zero_id[0]\n",
    "    stroke_end_id = np.where(x[i, :, 4] == 1)[0]\n",
    "    first_stroke_end_id = stroke_end_id[0]\n",
    "    \n",
    "    print(first_id, first_stroke_end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, d_z, hidden_size):\n",
    "        super().__init__()\n",
    "        self.lstm = L.LSTM(in_size=5, hidden_size=hidden_size)\n",
    "        self.mu_head = L.Linear(in_size=hidden_size, out_size=d_z)\n",
    "        self.sigma_head = L.Linear(in_size=hidden_size, out_size=d_z)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_z = d_z\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden = self.lstm(inputs)\n",
    "\n",
    "        mu = self.mu_head(hidden)\n",
    "        sigma_hat = self.sigma_head(hidden)\n",
    "        sigma = F.exp(sigma_hat / 2.)\n",
    "\n",
    "        xp = dezero.cuda.get_array_module(mu.data)\n",
    "        z = mu + sigma * xp.random.normal(0, 1, mu.shape)\n",
    "        return z, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, d_z, hidden_size, n_distributions):\n",
    "        super().__init__()\n",
    "        self.lstm = L.LSTM(in_size=d_z+5, hidden_size=hidden_size)\n",
    "\n",
    "        self.init_state = L.Linear(in_size=d_z, out_size=2*hidden_size)\n",
    "\n",
    "        self.mixtures = L.Linear(in_size=hidden_size, out_size=6 * n_distributions)\n",
    "        self.q_head = L.Linear(in_size=hidden_size, out_size=3)\n",
    "\n",
    "        self.n_distributions = n_distributions\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, inputs, z, state=None):\n",
    "        xp = dezero.cuda.get_array_module(x.data)\n",
    "        if state == None:\n",
    "            h, c = xp.split(self.init_state(z).data, 2, axis=2)\n",
    "            state = (h, c)\n",
    "\n",
    "        self.lstm.set_state(state)\n",
    "\n",
    "        # hidden Needs to chagned to output of lstm\n",
    "        hidden = self.lstm(inputs)\n",
    "\n",
    "        q_logits = F.log_softmax(self.q_head(hidden))\n",
    "\n",
    "        pi_logits, mu_x, mu_y, sigma_x, sigma_y, rho_xy = xp.split(self.mixtures(hidden).data, 6, 2)\n",
    "\n",
    "        bgm = BivariateGaussianMixture(pi_logits, mu_x, mu_y, F.exp(sigma_x), F.exp(sigma_y), F.tanh(rho_xy))\n",
    "        return bgm, q_logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReconstructionLoss(target, mask, bgm, q_logits):\n",
    "    xp = cuda.get_array_module(mask)\n",
    "    xy = target[:, :, 0:2]\n",
    "    xy = xy[:, :, xp.newaxis, :]\n",
    "    xy = xp.tile(xy, (1, 1, bgm.n_distributions, 1))\n",
    "    \n",
    "    # expanded_shape = (xy.shape[0], xy.shape[1], bgm.n_distributions, xy.shape[3])\n",
    "    \n",
    "    x = xy[:,:,:,0]\n",
    "    y = xy[:,:,:,0]\n",
    "\n",
    "    print(xy.shape, target.shape, x.shape, y.shape)\n",
    "    \n",
    "    loss_stroke = F.mul(bgm.get_lossfunc(x, y), mask)\n",
    "    \n",
    "    loss_pen = -F.mean(F.mul(target[:,:,2:], q_logits))\n",
    "    \n",
    "    return F.add(loss_stroke, loss_pen)\n",
    "\n",
    "def KLDivergenceLoss(mu, sigma):\n",
    "    xp = cuda.get_array_module(mu)\n",
    "    tmp = xp.ones(sigma.shape)\n",
    "    inner_1 = F.add(tmp, sigma)\n",
    "    inner_2 = F.add(F.pow(mu, 2), F.exp(sigma))\n",
    "    inner = F.sub(inner_1, inner_2)\n",
    "    tmp2 = xp.ones(inner.shape) * -2\n",
    "    return F.mean(F.div(inner, tmp2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, d_z, enc_hidden_size, dec_hidden_size, n_distributions):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_z, enc_hidden_size)\n",
    "        self.decoder = Decoder(d_z, dec_hidden_size, n_distributions)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        z, mu, sigma = self.encoder(x)\n",
    "\n",
    "        inputs = np.concatenate((x.data, z.data), axis=2)\n",
    "        inputs = dezero.as_variable(inputs)\n",
    "        bgm, q_logits = self.decoder(inputs, z)\n",
    "\n",
    "        kl_loss = KLDivergenceLoss(mu, sigma)\n",
    "        recon_loss = ReconstructionLoss(x, t, bgm, q_logits)\n",
    "        \n",
    "        return kl_loss + recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z = 4\n",
    "enc_hidden_size = 32\n",
    "dec_hidden_size = 64\n",
    "n_distributions = 8\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 64, 4), (4, 64, 4), (4, 64, 4))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(d_z, enc_hidden_size)\n",
    "z, mu, sigma = encoder(x)\n",
    "z.shape ,mu.shape, sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64, 5) (4, 64, 4)\n",
      "(4, 64, 9)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(d_z, dec_hidden_size, n_distributions)\n",
    "\n",
    "print(x.shape, z.shape)\n",
    "\n",
    "# x의 마지막 요소를 제외하고 가져와서 inputs 생성\n",
    "inputs = np.concatenate((x.data, z.data), axis=2)\n",
    "inputs = dezero.as_variable(inputs)\n",
    "\n",
    "print(inputs.shape)\n",
    "decoder(inputs, z)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64, 8, 2) (4, 64, 5) (4, 64, 8) (4, 64, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\functions.py:115: RuntimeWarning: invalid value encountered in log\n",
      "  y = xp.log(x)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (64,64,4) and (4,64,3) not aligned: 4 (dim 2) != 64 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(x, t)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcleargrads()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\core.py:130\u001b[0m, in \u001b[0;36mVariable.backward\u001b[1;34m(self, retain_grad, create_graph)\u001b[0m\n\u001b[0;32m    127\u001b[0m gys \u001b[38;5;241m=\u001b[39m [output()\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39moutputs]  \u001b[38;5;66;03m# output is weakref\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m using_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_backprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, create_graph):\n\u001b[1;32m--> 130\u001b[0m     gxs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gxs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    132\u001b[0m         gxs \u001b[38;5;241m=\u001b[39m (gxs,)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\functions.py:350\u001b[0m, in \u001b[0;36mLinear.backward\u001b[1;34m(self, gy)\u001b[0m\n\u001b[0;32m    348\u001b[0m gb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m b\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sum_to(gy, b\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    349\u001b[0m gx \u001b[38;5;241m=\u001b[39m matmul(gy, W\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m--> 350\u001b[0m gW \u001b[38;5;241m=\u001b[39m \u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gx, gW, gb\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\functions.py:336\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(x, W)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatmul\u001b[39m(x, W):\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\core.py:207\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    204\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [as_variable(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m    206\u001b[0m xs \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m--> 207\u001b[0m ys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ys, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    209\u001b[0m     ys \u001b[38;5;241m=\u001b[39m (ys,)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\흠\\Sketch-RNN\\dezero\\functions.py:325\u001b[0m, in \u001b[0;36mMatMul.forward\u001b[1;34m(self, x, W)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, W):\n\u001b[1;32m--> 325\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (64,64,4) and (4,64,3) not aligned: 4 (dim 2) != 64 (dim 1)"
     ]
    }
   ],
   "source": [
    "model = VAE(d_z, enc_hidden_size, dec_hidden_size, n_distributions)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(strokes.max_iter):\n",
    "        x, t = strokes.__next__()\n",
    "        loss = model(x, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        model.update()\n",
    "        print(loss)\n",
    "        \n",
    "    print(f\"Epoch {epoch} finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
